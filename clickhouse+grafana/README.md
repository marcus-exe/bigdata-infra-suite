# ğŸ“Š ClickHouse + Grafana + Data Generator

This project provides a ready-to-run environment using **ClickHouse** for high-performance OLAP storage, **Grafana** for visualization, and a **Python-based data generator** to simulate manufacturing station data.

## ğŸ—‚ Project Structure

```
.
â”œâ”€â”€ clickhouse_init/
â”‚   â””â”€â”€ init.sh                       # Initializes the ClickHouse DB and tables
â”œâ”€â”€ data_generator/
â”‚   â”œâ”€â”€ app.py                        # Python script generating sample data
â”‚   â””â”€â”€ Dockerfile                    # Dockerfile for building the generator
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ provisioning/
â”‚       â””â”€â”€ datasources/
â”‚           â””â”€â”€ clickhouse-datasource.yaml # Auto-configures ClickHouse in Grafana
â”œâ”€â”€ docker-compose.yml               # Orchestration of services
â””â”€â”€ README.md                        # You're here!
```

---

## ğŸ§° Services Overview

### ğŸš€ ClickHouse

* **Purpose**: Stores workstation production records with time-based partitioning and TTL cleanup.
* **Ports**:

  * `8123`: HTTP interface
  * `9000`: Native client interface
  * `9440`: TLS interface
* **Volume**: Persists data in `clickhouse_data`.

### ğŸ“ˆ Grafana

* **Purpose**: Visualize the data from ClickHouse.
* **Port**: `3000` (visit [http://localhost:3000](http://localhost:3000))
* **Auto-provisioned datasource**: Configured via `clickhouse-datasource.yaml`.

### âš™ï¸ Data Generator

* **Purpose**: Continuously inserts realistic random records into `workstation_records` table.
* **Config**: Reads connection info from `.env.development`.
* **Build**: Docker image is built from `data_generator/Dockerfile`.

---

## ğŸ’¾ Database Table: `workstation_records`

| Column               | Type             | Description                        |
| -------------------- | ---------------- | ---------------------------------- |
| `record_id`          | UUID             | Auto-generated unique ID           |
| `product_id`         | UInt32           | Simulated product ID               |
| `production_line_id` | UInt16           | Line ID where the product was made |
| `station_id`         | UInt16           | Workstation ID                     |
| `production_plan_id` | UInt16           | Associated production plan         |
| `defect_id`          | Nullable(UInt16) | Defect code (nullable)             |
| `produced_quantity`  | UInt16           | Quantity produced                  |
| `has_defect`         | UInt8 (0/1)      | Indicates if there was a defect    |
| `registered_at`      | DateTime64(3)    | Record timestamp with ms precision |
| `data_sended`        | Bool             | Whether data was already sent      |

ğŸ§  **TTL**: Records are automatically deleted **12 months** after `registered_at`.

---

## â–¶ï¸ Getting Started

### 1. Clone and Navigate

```bash
git clone https://github.com/marcus-exe/bigdata-infra-suite.git
cd bigdata-infra-suite/clickhouse+grafana
```

### 2. Create `.env.development` files

#### At root (ClickHouse and Grafana)

```env
CLICKHOUSE_DB=production_data
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=admin
GF_INSTALL_PLUGINS=grafana-clickhouse-datasource
```

#### Inside `data_generator/`

```env
CLICKHOUSE_HOST=clickhouse
CLICKHOUSE_PORT=9000
CLICKHOUSE_DB=production_data
CLICKHOUSE_USER=clickhouse_server_user
CLICKHOUSE_PASSWORD=salcomp_password
```

### 3. Run Everything

```bash
docker-compose up --build
```

### 4. Access Grafana

* Go to: [http://localhost:3000](http://localhost:3000)
* Default login: `admin` / `admin`

---

## ğŸ”„ Example Inserted Data

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ record_id                            â”‚ product_id â”‚ production_line_id â”‚ station_id â”‚ production_plan_id â”‚ defect_id â”‚ produced_quantity â”‚ has_defect â”‚ registered_at           â”‚ data_sended â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ fbe93c75-d149-4e1b-bc51-20b67f8d0fe7 â”‚       1379 â”‚                  9 â”‚          1 â”‚                104 â”‚     NULL  â”‚                40 â”‚          0 â”‚ 2025-07-01 14:43:30.262 â”‚ false       â”‚
â”‚ ...                                  â”‚        ... â”‚                ... â”‚        ... â”‚                ... â”‚     ...   â”‚              ...  â”‚        ... â”‚ ...                     â”‚ ...         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Development Notes

* The `data_generator` has a startup delay (`sleep(15)`) to wait for ClickHouse readiness.
* UUIDs and timestamps are auto-generated inside `app.py`.
* ClickHouse `init.sh` script ensures the table is created if not already present.

---

## ğŸ“¦ Stopping & Cleaning Up

```bash
docker-compose down -v
```

---

## ğŸ“Œ Todo Ideas

* [ ] Add dashboard provisioning JSON to Grafana
* [ ] Parametrize data generator frequency and ranges
* [ ] Add alerting in Grafana
